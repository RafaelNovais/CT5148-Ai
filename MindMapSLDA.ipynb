{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmrf7cONC7/UW34tdd7mZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/MindMapSLDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a480rTUr9PSl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning outcomes\n",
        "• LO1: Be able to define large-scale data analytics and understand its characteristics\n",
        "\n",
        "    1.   Distributed Sources data on the web\n",
        "    2.   Processed using diistributed and parallel computing approaches\n",
        "    3.   Distributed processing using multiple networked machines\n",
        "    \n",
        "\n",
        "\n",
        "• LO2: Be able to explain and apply concepts and tools for distributed and parallel processing of large-scale data\n",
        "\n",
        "    1.   Concurrency means that two or more computing processes or threads can run in an unordered, partially ordered or overlapping way, without affecting the overall result\n",
        "    2.   Concurrency can happen on the level of entire processes, or within a single process on the thread-level (multithreading; concurrency of threads)\n",
        "\n",
        "\n",
        "\n",
        "• LO3: Know how to explain and apply concepts and tools for highly scalable collection, querying,\n",
        "filtering, sorting and synthesizing of data\n",
        "\n",
        "\n",
        "• LO4: Know how to describe and apply selected statistical and machine learning techniques and tools\n",
        "for the analysis of large-scale data\n",
        "\n",
        "\n",
        "• LO5: Know how to explain and apply approaches to stream data analytics and complex event\n",
        "processing\n",
        "\n",
        "\n",
        "• LO6: Understand and be able to discuss privacy issues in connection with large-scale data analytics\n",
        "\n",
        "\n",
        "Planned for the rest of the semester\n",
        "• Revision of advanced Java programming concepts (mainly parallel computing)\n",
        "• Relevant new Java 8 concepts (e.g., Java 8 streams, Lambda expressions)\n",
        "  \n",
        "#  Functional programming\n",
        "\n",
        "    • Avoid mutation (in-place modification of existing data instead of reating a new (modified object), where possible\n",
        "    • Avoid global variables (e.g., public static fields)\n",
        "    • Avoid side effects of functions. The results of functions/methods should ideally only depend on their arguments. Methods/functions should not   manipulate shared state, as far as possible.\n",
        "    • Where possible, rely on inherently \"parallel\" data structures instead of designing parallel solutions manually (e.g., use parallel streams with Java8\n",
        "\n",
        "\n",
        "# Anonymous classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Lambda expressions\n",
        "\n",
        "    \n",
        "    *Lambda expressions are anonymous functions (functions without names)\n",
        "    *(int x, int y) -> x + y\n",
        "    *Parameters are optional. If there are no parameter, write () before the arrow\n",
        "    *Lambda expressions can use arbitrary blocks of code to produce a result\n",
        "    *You can provide a lambda expression everywhere where an object with a matching functional interface as type is expected\n",
        "    *\n",
        "\n",
        "\n",
        "```\n",
        "Ex:\n",
        "(int x, int y) -> x + y\n",
        "\n",
        "x -> {\n",
        "double d = 5.0;\n",
        "System.out.println(\"x: \" + x);\n",
        "double dx = d * x;\n",
        "return dc - 7.2;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "# Synchronized:\n",
        "Very general and good performance (if used correctly) but error-prone. Can degrade performance if used incorrectly (over-blocking):\n",
        "\n",
        "\n",
        "# Deadlock\n",
        "\n",
        "\n",
        "\n",
        "# ParallelStream\n",
        "\n",
        "\n",
        "# MapReduce\n",
        "\n",
        "    * MapReduce makes only sense if operations can be distributed across multiple machines and multiple cores on individual machines\n",
        "    * Cluster of machines, multi- and many-core computing (including multithreading and GPUs)\n",
        "    * Analogously for reduce shuffle\n",
        "\n",
        "    \n",
        "*  The Data Analytics pipeline\n",
        "* The MapReduce approach\n",
        "* Introduction to cluster computing and Hadoop\n",
        "* Introduction to Apache Spark\n",
        "* Working with RDDs (Resilient Distributed Datasets)\n",
        "* Spark Data Frames and Data Sets\n",
        "* Obtaining statistics over data\n",
        "* Representing and storing data\n",
        "* Deployment of LSDA tasks on a cluster of computers\n",
        "* Basics of parallel and clustered machine learning\n",
        "* Machine Learning with Spark (e.g., for classification)\n",
        "* Stream and event data analytics\n",
        "\n",
        "#Spark\n",
        "* Basic distributed data structures:\n",
        "* RDDs (Resilient Distributed Datasets): easy to use, intuitive, stable and flexible - but not the most efficient, i.a. due to large overhead for serialization)  Stored in RAM, Immutable , Distributed storage and processing\n",
        "* DataFrame (since Spark 1.3): fast, stable, close to SQL (not natural to use for non-SQL experts), restricted expressiveness compared to RDDs, works best with Scala\n",
        "* Datasets (since Spark 1.6 as a preview, fully supported since Spark 2.0): sort of mix between RDDs and DataFrames, fast but not fully stable yet\n",
        "* We will start with RDDs (because they are conceptually close to Java 8 Streams\n",
        "and partially underlying DataFrames/sets) and later also cover DataFrames and\n",
        "Datasets\n",
        "\n",
        "\n",
        "# Descriptions of some of them on the following slides\n",
        "```\n",
        "• map\n",
        "• filter\n",
        "• groupBy\n",
        "• sort\n",
        "• union\n",
        "• join\n",
        "• leftOuterJoin\n",
        "• rightOuterJoin\n",
        "• flatMap\n",
        "• reduce\n",
        "• count\n",
        "• fold\n",
        "• reduceByKey\n",
        "• groupByKey\n",
        "• cogroup\n",
        "• cross\n",
        "• zip\n",
        "• cartesian\n",
        "• sample\n",
        "• take\n",
        "• first\n",
        "• partitionBy\n",
        "• mapWith\n",
        "• pipe\n",
        "• distinct\n",
        "• save\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "84WI01qHGkQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Same example using Spark and Scala (including parsing)\n",
        "val textFile = spark.textFile(\"hdfs://...\")\n",
        "val counts = textFile.flatMap(line => line.split(\" \"))\n",
        ".map(word => (word, 1))\n",
        ".reduceByKey(_ + _)\n",
        "counts.saveAsTextFile(\"hdfs://...\")\n"
      ],
      "metadata": {
        "id": "-aUN_2Wno3qG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}