{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCK2PLonZytzQNIin9/qnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pOU1P0eb_BK"
      },
      "outputs": [],
      "source": [
        "import org.apache.spark.sql.Dataset;\n",
        "import org.apache.spark.sql.Row;\n",
        "import org.apache.spark.sql.SparkSession;\n",
        "import org.apache.spark.ml.clustering.KMeans;\n",
        "import org.apache.spark.ml.clustering.KMeansModel;\n",
        "import org.apache.spark.ml.feature.VectorAssembler;\n",
        "import org.apache.spark.ml.Pipeline;\n",
        "import org.apache.spark.ml.PipelineModel;\n",
        "import org.apache.spark.sql.functions;\n",
        "\n",
        "public class TweetClustering {\n",
        "\n",
        "    public static void main(String[] args) {\n",
        "        // Create SparkSession\n",
        "        SparkSession spark = SparkSession.builder()\n",
        "                .appName(\"Tweet Clustering\")\n",
        "                .master(\"local[*]\") // Set master to run locally\n",
        "                .getOrCreate();\n",
        "\n",
        "        // Load tweets data into DataFrame\n",
        "        Dataset<Row> tweetsDF = spark.read().option(\"header\", true).csv(\"tweets.csv\");\n",
        "\n",
        "        // Load city data into DataFrame\n",
        "        Dataset<Row> cityDF = spark.read().option(\"header\", true).csv(\"cities.csv\");\n",
        "\n",
        "        // Join tweetsDF and cityDF based on tweet_location and city_name\n",
        "        Dataset<Row> joinedDF = tweetsDF.join(cityDF,\n",
        "                                    functions.lower(tweetsDF.col(\"tweet_location\"))\n",
        "                                    .equalTo(functions.lower(cityDF.col(\"name\"))), \"left\");\n",
        "\n",
        "        // Select relevant columns for clustering\n",
        "        Dataset<Row> selectedDF = joinedDF.select(\"tweet_text\", \"latitude\", \"longitude\");\n",
        "\n",
        "        // Drop rows with missing or null location-related properties\n",
        "        selectedDF = selectedDF.filter(\"latitude is not null AND longitude is not null\");\n",
        "\n",
        "        // Assemble feature vector\n",
        "        VectorAssembler assembler = new VectorAssembler()\n",
        "                .setInputCols(new String[]{\"latitude\", \"longitude\"})\n",
        "                .setOutputCol(\"features\");\n",
        "\n",
        "        // Initialize KMeans model\n",
        "        KMeans kmeans = new KMeans()\n",
        "                .setK(100) // Number of clusters\n",
        "                .setSeed(12345L); // Set seed for reproducibility\n",
        "\n",
        "        // Create pipeline\n",
        "        Pipeline pipeline = new Pipeline()\n",
        "                .setStages(new PipelineStage[]{assembler, kmeans});\n",
        "\n",
        "        // Fit pipeline to data\n",
        "        PipelineModel model = pipeline.fit(selectedDF);\n",
        "\n",
        "        // Get cluster predictions\n",
        "        Dataset<Row> predictions = model.transform(selectedDF);\n",
        "\n",
        "        // Print tweet texts and their respective cluster indexes (predictions) for 1000 tweets\n",
        "        Dataset<Row> sampledPredictions = predictions.limit(1000);\n",
        "        sampledPredictions.select(\"tweet_text\", \"prediction\").show(false);\n",
        "\n",
        "        // Save model\n",
        "        model.write().overwrite().save(\"tweet_clustering_model\");\n",
        "\n",
        "        // Stop SparkSession\n",
        "        spark.stop();\n",
        "    }\n",
        "}\n"
      ]
    }
  ]
}