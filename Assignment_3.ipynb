{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rafael Novais de Melo -\n",
        "23113607**"
      ],
      "metadata": {
        "id": "XoDBgUxtdcpv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsK6oiuNTGfN"
      },
      "source": [
        "### Problem definition\n",
        "\n",
        "A company ABC have 1238 employees. ABC wants to buy a new insurance policy for its employees. Attach is a dataset (train-2.csv Download train-2.csv) about some of their previous employees where the company paid medical costs billed by a health insurance company XYZ. The total cost was 16410282.7 euros.\n",
        "\n",
        "ABC recently recruited about 100 additional employees. XYZ gave them a high price (i.e. 17755825 euros) for the same policy considering there will be additional 100 employees.\n",
        "\n",
        "You are working in ABC as a data analyst/research engineer. Your boss asked you to rapidly use the existing data that you have to see whether the given price is reasonable or not. Can you accurately predict the costs for the new employees based on their given information? Report the total price (17755825 euros) that is the previous total price (16410282.7) plus the new predicted price for the new employees with specific features given in the testing set (test-3.csv Download test-3.csv).\n",
        "\n",
        "Do the following:\n",
        "\n",
        "First, report what type of algorithm you need to use and why? [1 Mark]\n",
        "Use all the techniques of pre-processing, cleaning, and normalisation to prepare your data. Report each with justification why you want to use. [3 Marks]\n",
        "Analyse the data by visualising each feature or overall whole dataset with various graphs, bars, etc. to understand the data before applying a model. Report what you learned from visualising the data. Did you find any correlation or discrepancies in the data. [3 Marks]\n",
        "Use the k-fold cross validation approach to find the optimal model that you can apply on the testing data provided. Report the performance e.g loss and loss curve,  validation accuracy and its curve (if applicable) and show when and why you stopped e.g., did you reached convergence or not. [2.75 Marks]\n",
        "Report the final total price that you got. [0.25 Marks]\n",
        "This time you need to apply and present the results in the best way possible to your boss. Considering you have learned various ways.\n",
        "\n",
        "Upload your pdf of not more than 4 pages in the area designated for pdf upload.\n",
        "\n",
        "In addition, upload the code in the designated area for code upload. Plagiarism will be strictly penalised."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "flWkipQVTGfT"
      },
      "outputs": [],
      "source": [
        "#import Liberies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import ConvexHull\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import seaborn as sns\n",
        "from scipy.spatial import ConvexHull\n",
        "import requests\n",
        "from io import StringIO\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Read csv file to train and test\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train-2.csv')\n",
        "#df = upload_file()\n",
        "\n",
        "\n",
        "#Preparing the Data\n",
        "cleaned_df = clean_df(df)\n",
        "\n",
        "\n",
        "#Select the Target Colunm name\n",
        "target_column_name =  select_target(cleaned_df)\n",
        "\n",
        "\n",
        "#Visualization and Graphioc Analise\n",
        "analyze_data(cleaned_df, target_column_name, categorical_cols)\n",
        "\n",
        "\n",
        "#Select data and split in Train and Test\n",
        "x_train, x_test, y_train, y_test  = split_data(cleaned_df, target_column_name)\n",
        "\n",
        "\n",
        "#I Couldn't use Kfold with encode the categorical variable to predict so i return split_test_train\n",
        "#kfold_splits = split_data_kfold(df_encode, target_column_name)\n",
        "\n",
        "\n",
        "#Encode the categorical variables\n",
        "categorical_cols = select_cat(x_train)\n",
        "x_train_encode = encode_cat(x_train,categorical_cols)\n",
        "x_test_encode = encode_cat(x_test,categorical_cols)\n",
        "\n",
        "\n",
        "#Classification\n",
        "y_predict_rfr = class_random_forest_regressor(x_train_encode, y_train, x_test_encode)\n",
        "\n",
        "\n",
        "#Verifiy is the metrics from the classification\n",
        "r2_rfr = metrics(y_test,y_predict_rfr)\n",
        "total_y_predict_rfr = sum(y_predict_rfr)\n",
        "total_y_test = sum(y_test)\n",
        "print('Metrics from Test')\n",
        "print(total_y_predict_rfr,total_y_test,r2_rfr)\n",
        "\n",
        "#Read CSV file from the new employees\n",
        "new_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test-3.csv')\n",
        "#new_df = uploadfile()\n",
        "\n",
        "\n",
        "#Preparing the Data from the new employees\n",
        "x_new_df = new_df.drop(columns=target_column_name)\n",
        "new_x_cleaned_df = clean_df(x_new_df)\n",
        "\n",
        "\n",
        "#Encode the categorical variables Data from new employees\n",
        "x_encode = encode_cat(new_x_cleaned_df,categorical_cols)\n",
        "\n",
        "\n",
        "#Classification for the new employees\n",
        "predict_new_employees_rfr = class_random_forest_regressor(x_train_encode, y_train, x_encode)\n",
        "\n",
        "\n",
        "#Verifiy is the metrics from the classification for the new employees\n",
        "total_new_employees = sum(predict_new_employees_rfr)\n",
        "print('Total fom new Employees')\n",
        "total_new_employees\n",
        "\n",
        "\n",
        "#Compare High price and Predict Price\n",
        "old_price = 16410282.7\n",
        "new_price = 17755825\n",
        "diff_price = new_price - old_price\n",
        "print('Predict Price and High Price')\n",
        "total_new_employees,diff_price\n",
        "print('Difference between XYZ company is asking for the 100 employs and the amount we predict')\n",
        "diff_price-total_new_employees\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ay8ytioQWumd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Kfold with encode - DIDN'T Work\n",
        "kfold_splits = split_data_kfold(cleaned_df, target_column_name)\n",
        "all_predictions = []\n",
        "for fold, (x_train, x_test, y_train, y_test) in enumerate(kfold_splits, start=1):\n",
        "    # Assuming x_train and x_test are encoded (use x_train_encode, x_test_encode if needed)\n",
        "    y_pred_fold = class_random_forest_regressor(x_train, y_train, x_test)\n",
        "    all_predictions.append(y_pred_fold)\n",
        "    total_all_prediction = sum(all_predictions)\n",
        "\n",
        "\n",
        "    # Evaluate the predictions (you can use other metrics like mean squared error)\n",
        "    r2 = r2_score(y_test, y_pred_fold)\n",
        "    print(f'Fold {fold}: Mean Squared Error = {r2}')\n",
        "    print('Total')\n",
        "    total_all_prediction\n"
      ],
      "metadata": {
        "id": "XuIVG2gL0J2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload File\n",
        "\n",
        "def upload_file(): #Upload/Read csv file\n",
        "    file_path = input(\"Please enter the file path or URL to upload: \")\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "QkMhm3lnUtj9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the dataframe\n",
        "def clean_df(data):\n",
        "  cleaned_data = data.dropna()\n",
        "  return cleaned_data\n"
      ],
      "metadata": {
        "id": "D0q8vRIot6GS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Target column to y\n",
        "def select_target(data):\n",
        "    print(\"Columns in the DataFrame:\")  # Show all column names to select 2\n",
        "    for column in data.columns:\n",
        "        print(column)\n",
        "\n",
        "    column_name = input(\"Enter the name of the Target column: \")\n",
        "    return column_name\n",
        "\n",
        "    if column_name not in data.columns:\n",
        "        raise ValueError(\"Invalid column name. Please enter a valid column name.\")"
      ],
      "metadata": {
        "id": "qj5_vi3wJyfH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a data visualisation to identify Outliers\n",
        "def outliers(data,column_name):\n",
        "\n",
        "  z_scores = np.abs((data[column_name] - data[column_name].mean()) / data[column_name].std())\n",
        "  outliers_df = data[z_scores > 3]\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  sns.boxplot(x=data[column_name])\n",
        "  plt.title(f'Boxplot of {column_name} with Outliers Highlighted')\n",
        "  plt.scatter(x=outliers_df.index, y=outliers_df[column_name], color='red', label='Outliers')\n",
        "  plt.xlabel('Index')\n",
        "  plt.ylabel(column_name)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return outliers_df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6-UMer7BjrZo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data Using Kfold\n",
        "def split_data_kfold(data, column_name):\n",
        "    x_data = data.drop(columns=column_name)\n",
        "    y_data = data[column_name]\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=10)\n",
        "    splits = []\n",
        "    X_encoded = encode_cat(x_data,column_name)\n",
        "\n",
        "    for train_index, test_index in kf.split(X_encoded):\n",
        "        x_train, x_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
        "        y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
        "\n",
        "        splits.append((x_train, x_test, y_train, y_test))\n",
        "\n",
        "    return splits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hMShum-NXPP5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the Data into Train/Test\n",
        "def split_data(data,column_name):\n",
        "\n",
        "    x_data = data.drop(columns=column_name)  # Drop columns specified in column_name from x_data\n",
        "    y_data = data[column_name]\n",
        "\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=10)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "urdAYrwcUyKg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the columns are categorical\n",
        "def select_cat(x_data):\n",
        "    print(\"Columns in the DataFrame:\")\n",
        "    for column in df.columns:\n",
        "        print(column)\n",
        "\n",
        "    categorical_cols_str = input(\"Enter the names of categorical columns separated by ,: \")\n",
        "    categorical_cols = categorical_cols_str.split(',')\n",
        "    return categorical_cols"
      ],
      "metadata": {
        "id": "TAD8O9P_MI4H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical variables into numeric representations\n",
        "def encode_cat(x_data,categorical_cols):\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(), categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    x_encoded = preprocessor.fit_transform(x_data)\n",
        "\n",
        "    return x_encoded"
      ],
      "metadata": {
        "id": "f9248AtKIZVZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Regressor Classification\n",
        "def class_random_forest_regressor(x_train,y_train,x_test):\n",
        "    model = RandomForestRegressor(n_estimators=200 ,random_state=0)\n",
        "    model.fit(x_train,y_train)\n",
        "\n",
        "    predict = model.predict(x_test)\n",
        "\n",
        "    return predict\n",
        "\n"
      ],
      "metadata": {
        "id": "2eXi8nPl_30W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Classification\n",
        "def class_logistic_regression(x_train, y_train, x_test):\n",
        "  model = LogisticRegression()\n",
        "  model.fit(x_train,y_train)\n",
        "\n",
        "  predict = model.predict(x_test)\n",
        "\n",
        "  return predict\n"
      ],
      "metadata": {
        "id": "sLpatiMMlyqK"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-Fold Split and Validation to compare\n",
        "\n",
        "def k_fold_cross_validation(data,column_name):\n",
        "\n",
        "  x_data = data.drop(columns=column_name)  # Drop columns specified in column_name from x_data\n",
        "  y_data = data[column_name]\n",
        "\n",
        "  model = RandomForestRegressor()\n",
        "  kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "  losses = []\n",
        "\n",
        "  for train_index, val_index in kf.split(x_data):\n",
        "     X_train, X_val = x_data.iloc[train_index], x_data.iloc[val_index]\n",
        "     y_train, y_val = y_data.iloc[train_index], y_data.iloc[val_index]\n",
        "     model.fit(X_train, y_train)\n",
        "\n",
        "     y_val_pred = model.predict(X_val)\n",
        "\n",
        "     loss = mean_squared_error(y_val, y_val_pred)\n",
        "     losses.append(loss)\n",
        "\n",
        "  average_loss = np.mean(losses)\n",
        "  return average_loss\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YhfLj05xbRJ1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation Metrics Compare\n",
        "def metrics(y_test,y_pred):\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    return r2\n"
      ],
      "metadata": {
        "id": "yxdsSJDIERDt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization and Graphioc Analise\n",
        "def analyze_data(cleaned_df, target_column_name, categorical_cols):\n",
        "\n",
        "    # Correlation Analysis\n",
        "    correlation_matrix = cleaned_df.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Pair Plots\n",
        "    sns.pairplot(cleaned_df)\n",
        "    plt.show()\n",
        "\n",
        "    # Discrepancy Analysis\n",
        "\n",
        "\n",
        "\n",
        "    # Value Counts for Categorical Variables\n",
        "    for column in categorical_cols:\n",
        "        print(f'Value Counts for {column}:')\n",
        "        print(cleaned_df[column].value_counts())\n",
        "        print('\\n')\n",
        "\n",
        "    # Box Plots for Numerical Variables\n",
        "    for column in ['age', 'bmi', 'children']:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.boxplot(x=cleaned_df[column])\n",
        "        plt.title(f'Box Plot for {column}')\n",
        "        plt.show()\n",
        "\n",
        "    # Histograms for Numerical Variables\n",
        "    cleaned_df.hist(figsize=(10, 8))\n",
        "    plt.show()\n",
        "\n",
        "    # Bar Plots for Categorical Variables\n",
        "    for column in categorical_cols:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        cleaned_df[column].value_counts().plot(kind='bar')\n",
        "        plt.title(f'Bar Plot for {column}')\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TUBrGXEUpfFg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTqQuKZQLCF0",
        "outputId": "5b549bb1-1877-4333-9fd4-e74ac9615f47"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}