{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rafael Novais de Melo -\n",
        "23113607**"
      ],
      "metadata": {
        "id": "XoDBgUxtdcpv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsK6oiuNTGfN"
      },
      "source": [
        "# 1. Algorithm Choice\n",
        "Algorithm Selection: Random Forest Regressor\n",
        "For regression tasks predicting numerical values, the Random Forest Regressor is chosen. It's an ensemble learning method that combines multiple decision trees to make accurate and robust predictions. Random Forest is effective for capturing complex relationships in data and handles both numerical and categorical features. Although Logistic Regression was considered, its implementation complexity led to prioritizing Random Forest Regressor.\n",
        "# 2. Data Pre-processing\n",
        "Data Cleaning\n",
        "The initial step involves ensuring accuracy and consistency by handling missing values, removing duplicates, and addressing outliers.\n",
        "Data Normalization\n",
        "Numerical features are normalized to ensure that all features have the same scale, preventing certain features from dominating the learning process.\n",
        "Categorical Encoding\n",
        "Categorical variables ('sex', 'smoker', 'region') are encoded using one-hot encoding, converting them into a numerical format suitable for machine learning algorithms.\n",
        "# 3. Data Analysis\n",
        "Correlation Analysis\n",
        "Correlation matrices and pair plots are utilized to visualize relationships between numerical features, identifying potential correlations and understanding the data's structure.\n",
        "Discrepancy Analysis\n",
        "Value counts for categorical variables, box plots for numerical variables, and histograms are generated to identify any discrepancies or patterns in the data.\n",
        "# 4. K-fold Cross-Validation/Train-Test Split\n",
        "Model Training and Evaluation\n",
        "Due to challenges with K-fold cross-validation and categorical variable encoding, a train-test split is used. The Random Forest Regressor is trained on each fold, and the model's performance is evaluated using R-squared as the metric.\n",
        "Metrics from Test\n",
        "Predicted total cost: €1,812,585.72\n",
        "Actual total cost: €1,813,377.03\n",
        "Difference: -€791.31\n",
        "R-squared (R²): 0.8611\n",
        "Convergence and Stopping Criteria\n",
        "The model training continues until convergence or a predefined number of epochs. The stopping criteria include monitoring the validation loss to prevent overfitting.\n",
        "# 5. Results\n",
        "Final Prediction\n",
        "The total predicted cost for the new employees is €1,375,363.56. The difference between the insurance company's quoted price (€1,345,542.30) and the predicted total cost is €29,821.26, indicating that the predicted price is higher.\n",
        "Conclusion\n",
        "The project successfully employed the Random Forest Regressor to predict medical costs. The analysis, visualizations, and model evaluations provide valuable insights into the dataset and the model's predictive capabilities. The final prediction suggests a difference between the predicted and quoted prices, warranting further consideration in pricing negotiations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "flWkipQVTGfT"
      },
      "outputs": [],
      "source": [
        "#import Liberies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import ConvexHull\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import seaborn as sns\n",
        "from scipy.spatial import ConvexHull\n",
        "import requests\n",
        "from io import StringIO\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Read csv file to train and test\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train-2.csv')\n",
        "#df = upload_file()\n",
        "\n",
        "#Preparing the Data\n",
        "cleaned_df = clean_df(df)\n",
        "\n",
        "#Select the Target Colunm name\n",
        "target_column_name =  select_target(cleaned_df)\n",
        "\n",
        "#Visualization and Graphioc Analise\n",
        "analyze_data(cleaned_df, target_column_name, categorical_cols)\n",
        "\n",
        "#Verify is the data is normalizad removing categorical columns and if not normalizad the data\n",
        "is_normalizade, data_normalized = check_normalization(cleaned_df,categorical_cols)\n",
        "\n",
        "#Select data and split in Train and Test\n",
        "x_train, x_test, y_train, y_test  = split_data(cleaned_df, target_column_name)\n",
        "\n",
        "#I Couldn't use Kfold with encode the categorical variable to predict so i return split_test_train\n",
        "#kfold_splits = split_data_kfold(data_normalized, target_column_name)\n",
        "\n",
        "#Encode the categorical variables\n",
        "categorical_cols = select_cat(x_train)\n",
        "x_train_encode = encode_cat(x_train,categorical_cols)\n",
        "x_test_encode = encode_cat(x_test,categorical_cols)\n",
        "\n",
        "#Classification\n",
        "y_predict_rfr = class_random_forest_regressor(x_train_encode, y_train, x_test_encode)\n",
        "\n",
        "#Verifiy is the metrics from the classification\n",
        "r2_rfr = metrics(y_test,y_predict_rfr)\n",
        "total_y_predict_rfr = sum(y_predict_rfr)\n",
        "total_y_test = sum(y_test)\n",
        "print('Metrics from Test')\n",
        "print(total_y_predict_rfr,total_y_test,r2_rfr)\n",
        "\n",
        "#Read CSV file from the new employees\n",
        "new_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test-3.csv')\n",
        "#new_df = upload_file()\n",
        "\n",
        "#Preparing the Data from the new employees\n",
        "x_new_df = new_df.drop(columns=target_column_name)\n",
        "new_x_cleaned_df = clean_df(x_new_df)\n",
        "\n",
        "#Encode the categorical variables Data from new employees\n",
        "x_encode = encode_cat(new_x_cleaned_df,categorical_cols)\n",
        "\n",
        "#Classification for the new employees\n",
        "predict_new_employees_rfr = class_random_forest_regressor(x_train_encode, y_train, x_encode)\n",
        "\n",
        "#Verifiy is the metrics from the classification for the new employees\n",
        "total_new_employees = sum(predict_new_employees_rfr)\n",
        "print('Total fom new Employees')\n",
        "total_new_employees\n",
        "\n",
        "#Compare company High Price and Predict Price\n",
        "old_price = 16410282.7\n",
        "new_price = 17755825\n",
        "diff_price = new_price - old_price\n",
        "print('Predict Price and High Price')\n",
        "print(total_new_employees,diff_price)\n",
        "\n",
        "print('Difference between XYZ company is asking for the 100 employs and the amount we predict')\n",
        "diff_price-total_new_employees"
      ],
      "metadata": {
        "id": "ay8ytioQWumd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Kfold with encode - DIDN'T Work\n",
        "kfold_splits = split_data_kfold(data_normalized, target_column_name)\n",
        "all_predictions = []\n",
        "for fold, (x_train, x_test, y_train, y_test) in enumerate(kfold_splits, start=1):\n",
        "    # Assuming x_train and x_test are encoded (use x_train_encode, x_test_encode if needed)\n",
        "    y_pred_fold = class_random_forest_regressor(x_train, y_train, x_test)\n",
        "    all_predictions.append(y_pred_fold)\n",
        "    total_all_prediction = sum(all_predictions)\n",
        "\n",
        "\n",
        "    # Evaluate the predictions (you can use other metrics like mean squared error)\n",
        "    r2 = r2_score(y_test, y_pred_fold)\n",
        "    print(f'Fold {fold}: Mean Squared Error = {r2}')\n",
        "    print('Total')\n",
        "    total_all_prediction"
      ],
      "metadata": {
        "id": "XuIVG2gL0J2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload File\n",
        "\n",
        "def upload_file(): #Upload/Read csv file\n",
        "    file_path = input(\"Please enter the file path or URL to upload: \")\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df"
      ],
      "metadata": {
        "id": "QkMhm3lnUtj9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the dataframe\n",
        "def clean_df(data):\n",
        "  cleaned_data = data.dropna()\n",
        "  return cleaned_data"
      ],
      "metadata": {
        "id": "D0q8vRIot6GS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if the data is normalizad\n",
        "def check_normalization(data, categorical_cols):\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        data = data.drop(columns=categorical_cols)\n",
        "        data = data.values\n",
        "        mean_values = np.mean(data, axis=0)\n",
        "        std_dev_values = np.std(data, axis=0)\n",
        "        is_normalized = np.all(np.isclose(mean_values, 0, rtol=1e-3)) and np.all(np.isclose(std_dev_values, 1, rtol=1e-3))\n",
        "\n",
        "        if not is_normalized:\n",
        "            data_normalized = normalize_data(data, categorical_cols)\n",
        "            return is_normalized, data_normalized\n",
        "        else:\n",
        "            return is_normalized, data"
      ],
      "metadata": {
        "id": "bMjfOzSp5s8R"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Data\n",
        "def normalize_data(data, categorical_cols):\n",
        "\n",
        "  numeric_columns = [i for i in range(data.shape[1]) if i not in categorical_cols]\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
        "\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "xts5cdJj9fG_"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select Target column to y\n",
        "def select_target(data):\n",
        "    print(\"Columns in the DataFrame:\")  # Show all column names to select 2\n",
        "    for column in data.columns:\n",
        "        print(column)\n",
        "\n",
        "    column_name = input(\"Enter the name of the Target column: \")\n",
        "    return column_name\n",
        "\n",
        "    if column_name not in data.columns:\n",
        "        raise ValueError(\"Invalid column name. Please enter a valid column name.\")"
      ],
      "metadata": {
        "id": "qj5_vi3wJyfH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a data visualisation to identify Outliers\n",
        "def outliers(data,column_name):\n",
        "\n",
        "  z_scores = np.abs((data[column_name] - data[column_name].mean()) / data[column_name].std())\n",
        "  outliers_df = data[z_scores > 3]\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  sns.boxplot(x=data[column_name])\n",
        "  plt.title(f'Boxplot of {column_name} with Outliers Highlighted')\n",
        "  plt.scatter(x=outliers_df.index, y=outliers_df[column_name], color='red', label='Outliers')\n",
        "  plt.xlabel('Index')\n",
        "  plt.ylabel(column_name)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return outliers_df"
      ],
      "metadata": {
        "id": "6-UMer7BjrZo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data Using Kfold\n",
        "def split_data_kfold(data, column_name):\n",
        "    x_data = data.drop(columns=column_name)\n",
        "    y_data = data[column_name]\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=10)\n",
        "    splits = []\n",
        "    X_encoded = encode_cat(x_data,column_name)\n",
        "\n",
        "    for train_index, test_index in kf.split(X_encoded):\n",
        "        x_train, x_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
        "        y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
        "\n",
        "        splits.append((x_train, x_test, y_train, y_test))\n",
        "\n",
        "    return splits"
      ],
      "metadata": {
        "id": "hMShum-NXPP5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the Data into Train/Test\n",
        "def split_data(data,column_name):\n",
        "\n",
        "    x_data = data.drop(columns=column_name)  # Drop columns specified in column_name from x_data\n",
        "    y_data = data[column_name]\n",
        "\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=10)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "urdAYrwcUyKg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the columns are categorical\n",
        "def select_cat(x_data):\n",
        "    print(\"Columns in the DataFrame:\")\n",
        "    for column in df.columns:\n",
        "        print(column)\n",
        "\n",
        "    categorical_cols_str = input(\"Enter the names of categorical columns separated by ,: \")\n",
        "    categorical_cols = categorical_cols_str.split(',')\n",
        "    return categorical_cols"
      ],
      "metadata": {
        "id": "TAD8O9P_MI4H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical variables into numeric representations\n",
        "def encode_cat(x_data,categorical_cols):\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(), categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    x_encoded = preprocessor.fit_transform(x_data)\n",
        "\n",
        "    return x_encoded"
      ],
      "metadata": {
        "id": "f9248AtKIZVZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Regressor Classification\n",
        "def class_random_forest_regressor(x_train,y_train,x_test):\n",
        "    model = RandomForestRegressor(n_estimators=200 ,random_state=0)\n",
        "    model.fit(x_train,y_train)\n",
        "\n",
        "    predict = model.predict(x_test)\n",
        "\n",
        "    return predict"
      ],
      "metadata": {
        "id": "2eXi8nPl_30W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Classification\n",
        "def class_logistic_regression(x_train, y_train, x_test):\n",
        "  model = LogisticRegression()\n",
        "  model.fit(x_train,y_train)\n",
        "\n",
        "  predict = model.predict(x_test)\n",
        "\n",
        "  return predict"
      ],
      "metadata": {
        "id": "sLpatiMMlyqK"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-Fold Split and Validation to compare\n",
        "\n",
        "def k_fold_cross_validation(data,column_name):\n",
        "\n",
        "  x_data = data.drop(columns=column_name)  # Drop columns specified in column_name from x_data\n",
        "  y_data = data[column_name]\n",
        "\n",
        "  model = RandomForestRegressor()\n",
        "  kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "  losses = []\n",
        "\n",
        "  for train_index, val_index in kf.split(x_data):\n",
        "     X_train, X_val = x_data.iloc[train_index], x_data.iloc[val_index]\n",
        "     y_train, y_val = y_data.iloc[train_index], y_data.iloc[val_index]\n",
        "     model.fit(X_train, y_train)\n",
        "\n",
        "     y_val_pred = model.predict(X_val)\n",
        "\n",
        "     loss = mean_squared_error(y_val, y_val_pred)\n",
        "     losses.append(loss)\n",
        "\n",
        "  average_loss = np.mean(losses)\n",
        "  return average_loss"
      ],
      "metadata": {
        "id": "YhfLj05xbRJ1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation Metrics Compare\n",
        "def metrics(y_test,y_pred):\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    return r2"
      ],
      "metadata": {
        "id": "yxdsSJDIERDt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization and Graphioc Analise\n",
        "def analyze_data(cleaned_df, target_column_name, categorical_cols):\n",
        "\n",
        "    # Correlation Analysis\n",
        "    correlation_matrix = cleaned_df.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Pair Plots\n",
        "    sns.pairplot(cleaned_df)\n",
        "    plt.show()\n",
        "\n",
        "    # Discrepancy Analysis\n",
        "\n",
        "\n",
        "\n",
        "    # Value Counts for Categorical Variables\n",
        "    for column in categorical_cols:\n",
        "        print(f'Value Counts for {column}:')\n",
        "        print(cleaned_df[column].value_counts())\n",
        "        print('\\n')\n",
        "\n",
        "    # Box Plots for Numerical Variables\n",
        "    for column in ['age', 'bmi', 'children']:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.boxplot(x=cleaned_df[column])\n",
        "        plt.title(f'Box Plot for {column}')\n",
        "        plt.show()\n",
        "\n",
        "    # Histograms for Numerical Variables\n",
        "    cleaned_df.hist(figsize=(10, 8))\n",
        "    plt.show()\n",
        "\n",
        "    # Bar Plots for Categorical Variables\n",
        "    for column in categorical_cols:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        cleaned_df[column].value_counts().plot(kind='bar')\n",
        "        plt.title(f'Bar Plot for {column}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "TUBrGXEUpfFg"
      },
      "execution_count": 62,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}