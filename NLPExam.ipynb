{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUzKsUIClF4MqDYxwVbqDR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/NLPExam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 1: Linguistic Concepts\n",
        "\n",
        "#Important\n",
        "\n",
        "**Give the names of the linguistic levels of analysis that are concerned with:**\n",
        " i) word structure\n",
        "ii) sentence and phrase structure\n",
        "iii) meaning and reference\n",
        "\n",
        "i) Word structure: Morphology\n",
        "Concerned with the internal structure and formation of words, including roots, affixes, and word formation processes.\n",
        "\n",
        "ii) Sentence and phrase structure: Syntax\n",
        "Deals with the rules and principles governing the structure of sentences and phrases, focusing on how words combine to form grammatically correct sentences.\n",
        "\n",
        "iii) Meaning and reference: Semantics\n",
        "Focuses on the meaning of words, phrases, and sentences, as well as how they relate to the concepts and objects they refer to in the real world.\n",
        "Let me know if you want more details about any of these!\n",
        "\n",
        "------------------------------\n",
        "#Important\n",
        "**How many word types and tokens are there in the following sentence? Explain your reasoning.\n",
        "“The physical flow of gas into Ireland has remained stable and secure throughout the energy crisis, but gas security is now higher on the political agenda.”**\n",
        "\n",
        "\n",
        "Definitions:\n",
        "Word tokens: The total number of words in the sentence, counting repetitions.\n",
        "Word types: The number of unique words in the sentence, disregarding repetitions.\n",
        "\n",
        "Summary:\n",
        "Word tokens: 26\n",
        "\n",
        "Word types: 23\n",
        "\n",
        "\"The\" appears 3 times but counts as 1 type.\n",
        "\n",
        "\"Gas\" appears 2 times but counts as 1 type.\n",
        "\n",
        "All other words are unique.\n",
        "\n",
        "-------------------------------------\n",
        "**What is semantic role labeling? Give 1 example sentence with semantic role labels.**\n",
        "\n",
        "**Analise Semantica**\n",
        "\n",
        "Semantic Role Labeling (SRL) is the process of identifying the predicate-argument structure of a sentence by labeling words or phrases with their semantic roles. These roles describe the relationships between a verb (or predicate) and its arguments, answering questions such as \"Who did what to whom?\", \"When?\", and \"Where?\". Common semantic roles include Agent, Patient, Instrument, Location, and Time.\n",
        "\n",
        "-----------------------------------------------\n",
        "**What is a multi-word expression?**\n",
        "\n",
        "A multi-word expression (MWE) is a linguistic construction that consists of multiple words, but functions as a single unit with a specific meaning that may not be directly inferred from the individual meanings of its components. These expressions are often idiomatic or fixed in form and can appear across different levels of language, such as phrases, collocations, or compounds.\n",
        "\n",
        "Example: \"Kick the bucket\" (meaning \"to die\").\n",
        "\n",
        "Example: \"Look up\" (to search for information).\n",
        "\n",
        "Example: \"Toothbrush\" (a brush used for cleaning teeth).\n",
        "\n",
        "------------------------------------------------------\n",
        "**For the above calculate all unigram and bigram probabilities. You should treat “it’s”\n",
        "and “couldn’t” as single tokens. Treat the whole corpus as a single sentence.**\n",
        "\n",
        "```\n",
        "it's snowing it's falling\n",
        "the old lady is snoring\n",
        "she went to roof\n",
        "and she bumped her head\n",
        "and she couldn't get up in the morning\n",
        "```\n",
        "Unigram probabilities are computed based on the frequency of individual tokens.\n",
        "\n",
        "Bigram probabilities are calculated using the co-occurrence frequency of consecutive word pairs.\n",
        "---------------------------------------------------\n",
        "**Explain the difference between lexical and compositional semantics.**\n",
        "\n",
        "\n",
        " Lexical semantics deals with the meaning of individual words or lexical items, Lexical semantics looks at the inherent meaning of words themselves, including their senses, ambiguities, polysemy (multiple meanings of a word), synonymy (similar meanings), antonymy (opposite meanings), hyponymy (specific terms within broader categories), and so on.\n",
        "\n",
        " Compositional semantics deals with how the meanings of individual words combine to form the meaning of larger linguistic units, such as phrases and sentences. The principle of compositionality states that the meaning of a sentence can be derived from the meanings of its parts and the rules used to combine them.\n",
        "\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "Lexical Semantics is focused on the meaning of individual words and how they relate to each other within the language's vocabulary. It handles questions like What does a word mean? What are the relationships between words?\n",
        "\n",
        "Compositional Semantics is concerned with how the meanings of individual words combine to create the meaning of sentences. It explains how syntax and word meaning come together to convey complex meanings in larger linguistic structures.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Q2zy2AkycKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 3: Prompting\n",
        "**1 - List FOUR design considerations for using a prompting method with a large language model in order to solve an NLP task such as sentiment analysis.**\n",
        "\n",
        "When designing a prompting method to solve an NLP task like sentiment analysis using a large language model (LLM), consider the following four key factors:\n",
        "\n",
        "1. Prompt Clarity and Specificity\n",
        "Why it matters: A well-crafted prompt ensures that the model understands the task and minimizes ambiguity. Specificity directs the model to focus on relevant aspects of the input.\n",
        "Design tips:\n",
        "Clearly define the task in natural language (e.g., \"Classify the sentiment of the following text as positive, negative, or neutral.\").\n",
        "Use examples in the prompt to guide the model (e.g., \"Example 1: 'I love this movie!' → Positive\").\n",
        "2. Few-shot or Zero-shot Examples\n",
        "Description: Decide whether to use a zero-shot approach (no examples) or a few-shot approach (providing examples in the prompt). Few-shot examples help guide the model by demonstrating how the task should be performed.\n",
        "Example:\n",
        "Few-shot prompt:\n",
        "    *“Classify the sentiment of these sentences:\n",
        "    'I hate this product.' → Negative\n",
        "    'This is fantastic!' → Positive\n",
        "    Now classify the sentiment of: 'The service was okay.' →”*\n",
        "    Why It Matters: Few-shot prompts often improve accuracy by setting clear expectations, especially for nuanced tasks.\n",
        "3. Token and Context Limitations\n",
        "Description: LLMs have a maximum token limit, which includes both the prompt and the generated response. Ensure that the prompt is concise enough to fit within the model's token limit along with the input text and any desired output.\n",
        "Example: Instead of a verbose prompt:\n",
        "“Please analyze the sentiment of the provided text, and make sure to use precise language to describe the sentiment in your response.”\n",
        "Use:\n",
        "“Analyze the sentiment: 'Text here' (Positive/Negative/Neutral).”\n",
        "Why It Matters: A too-long prompt may be truncated, leading to incomplete or incorrect results.\n",
        "4. Handling Ambiguity and Edge Cases\n",
        "Description: Consider how the model should handle ambiguous or neutral inputs. Provide guidance or examples for cases where sentiment might be unclear or mixed.\n",
        "Example:\n",
        "“If the sentiment is unclear or mixed, respond with 'Neutral'. For example: 'The movie had good visuals but a boring plot.' → Neutral.”\n",
        "Why It Matters: Without explicit handling of edge cases, the model might produce inconsistent classifications.\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------\n",
        "**Assume that you have some known instance relations such as “Michael D Higgins” is the “President of Ireland”. Explain how you might use these relations and a large corpus of texts in order to develop prompts to extract this relation.**\n"
      ],
      "metadata": {
        "id": "6qYtkP97tJZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "**What does “GDPR” stand for? Give the full name and explain its purpose**\n",
        "\n",
        "GDPR stands for the General Data Protection Regulation.\n",
        "\n",
        "It is a regulation enacted by the European Union (EU) that came into effect on May 25, 2018. The GDPR aims to protect the privacy and personal data of individuals within the EU and the European Economic Area (EEA). It establishes strict guidelines on how organizations collect, store, manage, and use personal data, ensuring that individuals have more control over their own data.\n",
        "\n",
        "Enhance Data Privacy\n",
        "Ensure Transparency\n",
        "Data Security\n",
        "Accountability\n",
        "Consent\n",
        "\n",
        "--------------------------------------------------------\n",
        "**Briefly discuss 3 common challenges in sentiment analysis**\n",
        "\n",
        "Sentiment analysis, the process of determining the emotional tone or sentiment behind a piece of text, faces several challenges. Here are three common ones:\n",
        "Sarcasm and Irony:\n",
        "\n",
        "Context and Ambiguity:\n",
        "\n",
        "Multilingual, Informal Language:\n",
        "\n",
        "\n",
        "-------------------------------------------------------------------\n",
        "**Why can text or speech (language data) be viewed as personal data?**\n",
        "\n",
        "Text or speech (language data) can be viewed as personal data because it can directly or indirectly identify an individual or reveal personal information about them. Under data protection laws like the GDPR (General Data Protection Regulation) in the EU, personal data is defined as any information that relates to an identified or identifiable person. Here's why language data can be classified as personal data:\n",
        "\n",
        "1. Identification of Individuals:\n",
        "2. Revealing Personal Information\n",
        "3. Contextual Information\n",
        "\n",
        "-----------------------------------------------------------------------\n",
        "**List the four levels of risk identified in the EU AI Act, give an example of each, and explain your answer.**\n",
        "\n",
        "\n",
        "1. Minimal Risk:AI systems that pose little or no risk to individuals’ rights and freedoms. These systems are subject to minimal regulation.\n",
        "\n",
        "2. Limited Risk:AI systems that may have some risk but require specific transparency measures to ensure users are aware of their use.\n",
        "\n",
        "3. High Risk: AI systems that pose a significant risk to the safety, rights, or freedoms of individuals and are subject to stringent requirements and oversight.\n",
        "\n",
        "4. Unacceptable Risk:AI systems that pose an unacceptably high risk to people's safety or fundamental rights and are prohibited."
      ],
      "metadata": {
        "id": "zNNQ2G_n7Gu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHATBOT\n",
        "\n",
        "**Explain the difference between a task-oriented and an open-domain chatbot.**\n",
        "\n",
        "A task-oriented chatbot is designed to perform specific tasks or help with particular activities. It is goal-driven and focuses on completing particular actions, such as answering queries, making reservations, processing orders, or providing customer support for a product or service.\n",
        "\n",
        "1. Architecture - Most task-oriented systems are pipeline systems based on several levels of analysis As such they require a complete set of NLP tasks\n",
        "2. Dialogflow - Draw the flow with the tasks ChatBot should do.\n",
        "3. Semantic Tagging - Identify the elements and enity\n",
        "4. Discourse State Tracking -  The DST takes the semantic tagging from the current utterance and updates the global set of slots (discourse state)\n",
        "5. Policy Learning - Text Classification Try to find the class Case When\n",
        "6. Natural Language Generation - Pre-written responses with slots\n",
        "I have booked you a flight from *ORIGIN* to *DEST* on *DATE*\n",
        "7. End-to-end approaches - Instead, letʼs have a single neural network for the whole dialogue\n",
        "\n",
        "\n",
        "\n",
        "open-domain chatbot is designed to engage in more general, free-flowing conversations. It does not have a specific task it must complete but instead aims to maintain a natural, wide-ranging dialogue with users on a variety of topics.\n",
        "\n",
        "1. Sequence-to-sequence - We can view this as a seq2seq task taking questions and answers. N Inputs to N Outputs\n",
        "2. Hierarchical Recurrent Encoder Decoder (HRED) - Recurrent state is generated from encoder and previous recurrent state,Response generated from recurrent state.\n",
        "3. Coherence - Reinforcement learning is a technique to encourage good answers, Answers must be logical and consistent , REWARDS\n",
        "4. Diversity - System learns high frequency answers (“I donʼt knowˮ) and nearly always uses them. Diversity of answers must also be optimized for\n",
        "5. Empathy - Chatbot performance is often disappointing, Modules to detect user\n",
        "emotions and take actions are very useful.\n",
        "6. Topic and Knowledge - Real-world knowledge is challenging to embed as vectors, Explicitly optimizing to stay on topic can improve performance. Extra Knowledge.\n",
        "\n",
        "\n",
        "**Evaluation of Chatbots**\n",
        "\n",
        "* MT-style evaluation\n",
        "\n",
        "    Text Similarity/MT Evaluation\n",
        "    But different may not be wrong!\n",
        "\n",
        "**Other evaluation criteria**\n",
        "\n",
        "* Manual Evaluation\n",
        "\n",
        "    Task Completion: Did the user manage to complete the task?\n",
        "\n",
        "    Informativeness: Did the user gain something from talking to the agent?\n",
        "\n",
        "* Semi-automatic:\n",
        "\n",
        "    Coherence: Was the dialogue coherent?\n",
        "\n",
        "    Diversity: Was the dialogue diverse?\n",
        "\n",
        "    Fluency: Could the dialogue be understood?\n",
        "\n",
        "\n",
        "\n",
        "----------------------------------------------------------------\n",
        "\n",
        "**What is the difference between a generative system and a retrieval-based system for question answering.**\n",
        "\n",
        "A generative question-answering system generates answers from scratch, based on the input query and its understanding of the language. It doesn’t rely on pre-existing answers but instead produces a new response using a model trained on large datasets.(e.g., GPT-3, T5, BERT-based models)\n",
        "\n",
        "A retrieval-based system retrieves answers from a pre-existing set of information, such as a database, knowledge base, or a collection of documents. It uses methods like information retrieval (IR) and ranking algorithms to find the most relevant answer from a large corpus. TF-IDF, BM25,"
      ],
      "metadata": {
        "id": "MWhqxW5p9Exg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Models\n",
        "\n",
        "**Explain one limitation of a bigram language model compared to a language model that uses a neural network.**\n",
        "\n",
        "One significant limitation of a bigram language model compared to a neural network-based language model is its inability to capture long-term dependencies in text.\n",
        "\n",
        "* Limitation: Short Context Window:\n",
        "\n",
        "A bigram language model only considers the probability of a word based on the immediately preceding word. It uses a context window of size 1, which severely restricts its understanding of broader context.\n",
        "For example, in the sentence \"The cat sat on the mat because it was warm,\" a bigram model cannot determine that \"it\" refers to \"the mat\" or even maintain coherence over the entire sentence. It treats the prediction of \"it\" as solely dependent on \"because.\"\n",
        "\n",
        "* Neural Network-Based Language Models:\n",
        "\n",
        "Neural models (like LSTMs, GRUs, or transformers) can process longer contexts and learn dependencies over multiple words or even entire passages. For instance, in the same sentence, a transformer-based model (e.g., GPT) can infer that \"it\" likely refers to \"the mat,\" because it retains information from earlier parts of the sentence.\n",
        "\n",
        "\n",
        "-------------------------------------------------------------\n",
        "**Explain how a language model can be used in either a machine translation system OR a spelling correction system.**\n",
        "\n",
        "A language model can play a crucial role in a spelling correction system by evaluating the likelihood of word sequences and identifying the most probable intended text. Here’s how it works:\n",
        "\n",
        "\n",
        "-----------------------------------------------\n",
        "**Explain 3 limitation of a bigram language model compared to a language model that uses a neural network.**\n",
        "\n",
        "1. Limited Contextual Understanding\n",
        "\n",
        "**Bigram Model:**\n",
        "\n",
        "It only considers the immediate previous word when predicting the next word. This short context window means it cannot capture dependencies or relationships that span across multiple words.\n",
        "\n",
        "Example: In the sentence \"The cat sat on the mat because it was warm,\" the bigram model cannot connect \"it\" to \"the mat\". It treats each word pair independently, losing the broader context.\n",
        "\n",
        "\n",
        "**Neural Networks:**\n",
        "\n",
        " Neural models, such as transformers, can process longer sequences and retain information about the context across the entire sentence or paragraph.\n",
        "\n",
        "\n",
        "2. Poor Handling of Ambiguity and Complexity\n",
        "\n",
        "**Bigram Model:**\n",
        "\n",
        " Assumes independence between non-adjacent words, which limits its ability to resolve ambiguities or handle complex grammatical structures.\n",
        "Example: In the phrase \"bank near the river\", a bigram model cannot use the surrounding context to decide that \"bank\" refers to a geographical location rather than a financial institution.\n",
        "\n",
        "**Neural Networks:**\n",
        "\n",
        "Can leverage the global context to disambiguate words and understand complex structures, leading to more accurate predictions in diverse linguistic scenarios.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Po1Bm2dGakXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the difference between Zero-shot, Few-shot, Chain-of-thought and soft prompting **\n",
        "\n",
        "1. Zero-shot Prompting\n",
        "\n",
        "Description:\n",
        "The model is given only the task description or a question without any examples. It relies solely on its pretrained knowledge to generate a response.\n",
        "\n",
        "Use Case: When you want the model to infer the task directly from the prompt.\n",
        "\n",
        "Example:\n",
        "Prompt: “Translate the following sentence into French: ‘I love programming.’”\n",
        "Output: “J’aime programmer.”\n",
        "\n",
        "Advantages: Simple, requires no additional data or examples.\n",
        "\n",
        "Limitations: May struggle with tasks that require specific instructions or formatting.\n",
        "\n",
        "\n",
        "2. Few-shot Prompting\n",
        "\n",
        "Description:\n",
        "The model is provided with a few examples (often 1-5) of the task before the query. These examples act as context to guide the model's response.\n",
        "\n",
        "Use Case: When task-specific examples are necessary to help the model understand the format or nature of the task.\n",
        "\n",
        "Example:\n",
        "Prompt:*“Translate the following sentences into French:\n",
        "‘I love programming.’ → ‘J’aime programmer.’\n",
        "‘I enjoy reading books.’ → ?”*\n",
        "Output: “J’aime lire des livres.”\n",
        "\n",
        "Advantages: Improves performance for complex tasks without fine-tuning.\n",
        "\n",
        "Limitations: Limited by context length and can still fail with insufficient examples.\n",
        "\n",
        "\n",
        "3. Chain-of-thought Prompting (varias request para direcionar )\n",
        "\n",
        "Description:\n",
        "A technique where the model is encouraged to produce intermediate reasoning steps before arriving at the final answer. This helps with tasks requiring logical reasoning or multi-step calculations.\n",
        "\n",
        "Use Case: Tasks involving reasoning, math problems, or decision-making.\n",
        "\n",
        "Example:\n",
        "Prompt:\n",
        "“If there are 12 apples and you give away 5, how many apples are left?\n",
        "First, figure out how many apples are given away. Then subtract that number from the total.”\n",
        "Output:\n",
        "“You gave away 5 apples. 12 - 5 = 7. The answer is 7 apples.”\n",
        "\n",
        "Advantages: Boosts performance on tasks that require logic and step-by-step reasoning.\n",
        "\n",
        "Limitations: Requires careful crafting of prompts and doesn’t always generalize to tasks it wasn’t pretrained for.\n",
        "\n",
        "\n",
        "4. Soft Prompting\n",
        "\n",
        "Description:\n",
        "Involves learning embedding-based prompts rather than natural language text prompts. These prompts are optimized directly in the embedding space and appended to the input for a specific task.\n",
        "Unlike manual prompting, soft prompts are learned parameters and require additional training.\n",
        "\n",
        "Use Case: Fine-tuning tasks where subtle adjustments in the model’s input representation improve task-specific performance.\n",
        "\n",
        "Example: Optimized embeddings added to input to adjust how the model interprets the task, typically in research or advanced AI deployments.\n",
        "\n",
        "Advantages: Flexible and task-specific, often more effective than manual prompts.\n",
        "\n",
        "Limitations: Requires task-specific optimization and a labeled dataset."
      ],
      "metadata": {
        "id": "IgMupELv3OP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization\n",
        "\n",
        "**BERT (Bidirectional Encoder Representations from Transformers)**\n",
        "\n",
        "is a pre-trained transformer-based language model. Although BERT was primarily designed for tasks like question answering and sentence classification, it can also be fine-tuned or adapted for text summarization. Here's how BERT works in the context of summarization:\n",
        "\n",
        "BERT is most commonly used for extractive summarization due to its bidirectional context understanding.\n",
        "\n",
        "1. Input Representation\n",
        "The input text is tokenized using BERT’s tokenizer.\n",
        "Special tokens like [CLS] (for classification) and [SEP] (for sentence separation) are added to the text.\n",
        "Example:\n",
        "Original Text: \"The cat sat on the mat. It was warm and cozy.\"\n",
        "Tokenized Input: [CLS] The cat sat on the mat. [SEP] It was warm and cozy. [SEP]\n",
        "2. Encoding Sentences\n",
        "BERT processes the input text and produces contextualized embeddings for each token.\n",
        "These embeddings capture both the meaning of the token and its relationship with other tokens in the text.\n",
        "3. Sentence-Level Embeddings\n",
        "For summarization, sentence embeddings are extracted. The [CLS] token is often used as a summary of the corresponding sentence.\n",
        "4. Sentence Scoring\n",
        "Each sentence is scored based on its importance to the overall meaning of the text. This is done by training a classifier on top of BERT to assign scores.\n",
        "Example: Sentences about the main topic of the text will receive higher scores.\n",
        "5. Sentence Selection\n",
        "Based on the scores, the top-ranked sentences are selected to form the summary.\n",
        "Example: From \"The cat sat on the mat. It was warm and cozy. The dog barked outside.\", BERT might select \"The cat sat on the mat. It was warm and cozy.\"\n",
        "\n",
        "\n",
        "**Fine-Tuning BERT for Summarization**\n",
        "\n",
        "BERT can be fine-tuned for summarization tasks by:\n",
        "\n",
        "Training it on a labeled dataset where sentences are annotated as important or unimportant.\n",
        "Adjusting BERT’s output layer to predict the importance of sentences for extractive summarization.\n",
        "Using a summarization-specific loss function during fine-tuning.\n",
        "\n",
        "\n",
        "**Advantages of Using BERT for Summarization**\n",
        "\n",
        "Bidirectional Context: BERT understands the full context of words in a sentence, making it better at selecting meaningful sentences.\n",
        "\n",
        "High Accuracy: Outperforms many traditional extractive summarization techniques.\n",
        "Flexibility: Can be adapted to various domains with fine-tuning."
      ],
      "metadata": {
        "id": "ZlnnDFv6UD4V"
      }
    }
  ]
}