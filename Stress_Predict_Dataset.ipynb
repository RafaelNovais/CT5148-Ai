{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1U5Yc1N162c4TZkToIVQ0TKgNdapv0LTs",
      "authorship_tag": "ABX9TyNzXXPo0oRn3oeDpsNvmx7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/CT5148-Ai/blob/master/Stress_Predict_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DlozoDyiNbf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Rafael Novais de Melo\n",
        "2324-CT5170 Principles of Machine Learning\n",
        "23113607\n",
        "\n",
        "\n",
        "###Understanding the Dataset\n",
        "For solving the problem of predicting stress levels, \"Supervised Classification\" is the appropriate machine learning category.\n",
        "This choice is justified by the binary nature of the data. It allows us to make predictions using the training dataset and confirm their accuracy using the test dataset,\n",
        "providing a quantitative estimate of stress levels and a more fine-grained understanding of stress.\n",
        "\n",
        "\n",
        "\n",
        "###Data Exploration\n",
        "Analyzing the distribution of data between training and testing sets is crucial. To determine whether the dataset is imbalanced, we can look at the proportion of each class.\n",
        "Imbalanced datasets typically have one class significantly outnumbering the other, but in this case,\n",
        "it doesn't qualify as imbalanced as the proportion falls within the range of low to moderate imbalances (less than 20%).\n",
        "Data:\n",
        "Class 0: 67.28%\n",
        "Class 1: 32.72%\n",
        "Test:\n",
        "Class 0: 67.18%\n",
        "Class 1: 32.82%\n",
        "Train:\n",
        "Class 0: 67.32%\n",
        "Class 1: 32.68%\n",
        "\n",
        "\n",
        "\n",
        "###Choosing an ML Package\n",
        "To address the various tasks associated with machine learning and classification, we rely on different tools:\n",
        "Pandas: It is used for reading and manipulating data in various formats, facilitating data conversion, cleaning, and organization.\n",
        "Scikit-Learn: This library offers a wide range of classification algorithms, including Decision Trees, Random Forests, Support Vector Machines (SVM), and Linear Regression,\n",
        "making it a valuable choice.\n",
        "Matplotlib and Seaborn: These are used for data visualization and scientific plotting.\n",
        "NumPy: It helps organize the data and perform mathematical operations.\n",
        "\n",
        "\n",
        "\n",
        "###Data Pre-processing\n",
        "Before applying machine learning algorithms, data pre-processing is essential. This involves removing empty rows, structuring the data in a dataframe,\n",
        "and establishing a baseline for accuracy comparison. The baseline serves as a reference point, assuming all predictions are 1 (random chance).\n",
        "\n",
        "\n",
        "\n",
        "###Algorithm Selection and Application\n",
        "\n",
        "Two different classification algorithms are chosen:\n",
        "\n",
        "DecisionTreeClassifier: Initially, we set max_depth=5 to create a manageable visual representation. However, for improved precision and accuracy,\n",
        "it's better to remove the max_depth constraint. We use the confusion matrix to assess correct and incorrect predictions, verify recall,\n",
        "and calculate accuracy to compare with the baseline.\n",
        "\n",
        "Random Forest: Employed with 100 decision trees, as it outperformed single decision trees in precision.\n",
        "\n",
        "SVM: Unfortunately, SVM resulted in low accuracy and was not deemed trustworthy for this task.\n",
        "\n",
        "AdaBoostClassifier and K-Nearest Neighbors: Produced similar results, but with less precision compared to Random Forest.\n",
        "\n",
        "\n",
        "###Model Evaluation\n",
        "Given the health context of the problem, precision is considered the best metric. After applying various classification algorithms and calculating precision metrics,\n",
        "Random Forest emerged as the algorithm with the highest precision:\n",
        "Random Forest Precision = 0.6318\n",
        "\n",
        "\n",
        "\n",
        "###Comparative Analysis\n",
        "Both models provide different results, with Random Forest achieving the highest precision. The strengths and weaknesses of each algorithm's performance are reflected upon,\n",
        "taking into account factors like interpretability, accuracy, and the potential for overfitting or underfitting.\n",
        "The ability of the models to effectively predict stress levels is assessed in line with the assignment's objectives.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pandas.core.arrays.datetimelike import mode\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import graphviz\n",
        "!pip install graphviz\n",
        "!apt-get install graphviz\n",
        "\n",
        "\n",
        "\n",
        "###Data Pre-processing\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data.csv\")\n",
        "dataTest = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\")\n",
        "dataTrain = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "data = pd.DataFrame(data)\n",
        "data = data.dropna()\n",
        "dataTest = pd.DataFrame(dataTest)\n",
        "dataTest = dataTest.dropna()\n",
        "dataTrain = pd.DataFrame(dataTrain)\n",
        "dataTrain = dataTrain.dropna()\n",
        "\n",
        "x_data = data[[\"HR\",\"respr\"]]\n",
        "y_data = data[\"Label\"]\n",
        "x_test = dataTest[[\"HR\",\"respr\"]]\n",
        "y_test = dataTest[\"Label\"]\n",
        "x_train = dataTrain[[\"HR\",\"respr\"]]\n",
        "y_train = dataTrain[\"Label\"]\n",
        "\n",
        "\n",
        "###Data Exploration\n",
        "propor_data = y_data.value_counts()/len(x_data)\n",
        "propor_test = y_test.value_counts()/len(x_test)\n",
        "propor_train = y_train.value_counts()/len(x_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYe0QuMUKr-z",
        "outputId": "951afbd5-42ff-4002-8d3f-f0c041130b70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###BaseLine\n",
        "base_line = np.ones(len(y_test))\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(x_train,y_train)\n",
        "base_line_accuracy = accuracy_score(y_test,base_line)\n",
        "print(base_line_accuracy)\n"
      ],
      "metadata": {
        "id": "YdtXHd81-2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###Algorithm Selection and Application\n",
        "##Decision Tree Classifier\n",
        "model = DecisionTreeClassifier( random_state=0)\n",
        "model.fit(x_train,y_train)\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "###Model Evaluation\n",
        "accuracy = accuracy_score(y_test,predict)\n",
        "precision = precision_score(y_test,predict)\n",
        "confusion_matrix = confusion_matrix(y_test,predict)\n",
        "recall = recall_score(y_test,predict)\n",
        "print(accuracy, precision,recall ,confusion_matrix)\n",
        "#Print Graphic(max_depth=5)\n",
        "#dot_data = export_graphviz(model, feature_names=x_train.columns, class_names=[\"no\", \"yes\"] ,filled=True, rounded=True)\n",
        "#graphviz.Source(dot_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bao3az--UOC8",
        "outputId": "afd28c6e-7cdd-488b-813d-64c960ca3f75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7107844589989035 0.559023430513325 0.5642205975268526 [[17733  4931]\n",
            " [ 4828  6251]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200 ,random_state=0)\n",
        "model.fit(x_train,y_train)\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "###Model Evaluation\n",
        "accuracy = accuracy_score(y_test,predict)\n",
        "precision = precision_score(y_test,predict)\n",
        "confusion_matrix = confusion_matrix(y_test,predict)\n",
        "recall = recall_score(y_test,predict)\n",
        "print(accuracy, precision,recall ,confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PqK94K5C08C",
        "outputId": "9b522545-c759-46b5-a01b-246565ba1b80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7431170909521975 0.6317918443205423 0.5216174745013088 [[19296  3368]\n",
            " [ 5300  5779]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Support Vector Machine (SVM)\n",
        "model = LinearSVC(random_state=0)\n",
        "model.fit(x_train,y_train)\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "###Model Evaluation\n",
        "accuracy = accuracy_score(y_test,predict)\n",
        "precision = precision_score(y_test,predict)\n",
        "confusion_matrix = confusion_matrix(y_test,predict)\n",
        "recall = recall_score(y_test,predict)\n",
        "print(accuracy, precision,recall ,confusion_matrix)\n",
        "\n",
        "##Print Graphic\n",
        "##sns.countplot(x=\"HR\",y=\"respr\",col=\"Label\", hue=\"Label\",data=data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ViTVbojcdm3",
        "outputId": "44078db0-74ef-4ef9-f9e8-e500cd0d1f92"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6716652342708117 0.0 0.0 [[22664     0]\n",
            " [11079     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##AdaBoostClassifier\n",
        "model = AdaBoostClassifier(n_estimators=200 ,random_state=0)\n",
        "model.fit(x_train,y_train)\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "###Model Evaluation\n",
        "accuracy = accuracy_score(y_test,predict)\n",
        "precision = precision_score(y_test,predict)\n",
        "confusion_matrix = confusion_matrix(y_test,predict)\n",
        "recall = recall_score(y_test,predict)\n",
        "print(accuracy, precision,recall ,confusion_matrix)"
      ],
      "metadata": {
        "id": "80lBku7mXRKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c348b0a7-d188-4be7-b210-52a44149e698"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6812968615712889 0.5979505726341169 0.08953876703673616 [[21997   667]\n",
            " [10087   992]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##K-Nearest Neighbors\n",
        "model = KNeighborsClassifier(metric='euclidean', n_neighbors=100)\n",
        "model.fit(x_train,y_train)\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "###Model Evaluation\n",
        "accuracy = accuracy_score(y_test,predict)\n",
        "precision = precision_score(y_test,predict)\n",
        "confusion_matrix = confusion_matrix(y_test,predict)\n",
        "recall = recall_score(y_test,predict)\n",
        "print(accuracy, precision,recall ,confusion_matrix)\n"
      ],
      "metadata": {
        "id": "lbE59aE_0N2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb79548-9409-47c2-eebd-9c96cfc3c277"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7055981981448004 0.6212666807879687 0.26473508439389837 [[20876  1788]\n",
            " [ 8146  2933]]\n"
          ]
        }
      ]
    }
  ]
}