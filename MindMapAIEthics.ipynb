{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6S6ByLAZKE31c3EpUUeyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/MindMapAIEthics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 1\n",
        "\n",
        "**Embedded values (Nissenbaum) Valores incorporados**\n",
        "\n",
        "“the design and operation of computer system has moral consequences and therefore should be subjected to ethical analysis” (Brey 2009) it is possible to identify tendencies regarding promotion of particular values and norms for example, computer programs can be supportive of privacy, freedom of information, property rights or go against the realization of these values.\n",
        "\n",
        "Problem is when the questions about ethics just appear in the End, is diffulct to control.\n",
        "\n",
        "Technologies are not neutral\n",
        "\n",
        "E.g. common view of engineering as neutral service-provider for client who is responsible for ethical use Importance because: information technologies often not transparent to users, i.e. users cannot easily investigate technologies and their biases\n",
        "\n",
        "Like Guns doesn't kill people, people kill people.\n",
        "\n",
        "**Biases in computer systems Preconceitos**\n",
        "\n",
        "Definition: A system that systematically and unfairly discriminates against certain individuals or groups in favour of others E.g. credit rating system that instead of focusing on actual credit record bases its assessment on address or ethnic surname Predictive policing targeting minority populations that will disproportionately be affected by police scrutiny (e.g. minor drug possession charges when searches) Criminal justice parole assessment systems that discriminate against minorities Particularly problematic if no possibility of appeal/correction or validation and if a system becomes a standard (monopolist) in the field and no alternatives exist\n",
        "\n",
        "Pre-existing bias: computer system is designed by somebody who holds these biases and encodes them in the technology\n",
        "Technical bias: limitations of computer technology might lead to bias, or problems in achieving transition of concepts into technical realisation\n",
        "Emergent bias: arising from changing contexts of use, e.g. mismatch between users and system design\n",
        "\n",
        "**Accessibility as a value concern**\n",
        "\n",
        "Equal inclusion of persons with different capabilities and backgrounds as important value.\n",
        "\n",
        "Part of human rights requirements, e.g. Convention of the Rights of Persons with Disabilities.\n",
        "\n",
        "Goal of achieving “Universal design“, i.e. design solutions that facilitate accessibility for different disabilities, and other potential forms of exclusion Example: flight booking with visual impairment, “racist soap dispenser\n",
        "\n",
        "\n",
        "**Procedure of value sensitive design**\n",
        "\n",
        "\n",
        "Value-sensitive design refers to a theoretical approach that identifies and incorporates stakeholders’ values into the design process of a new technology. Especially when new technologies are developed that open up new ways of impacting human life. Proactive approach rather than reactive approach, i.e. identify issues before they occur rather than having to troubleshoot later\n",
        "\n",
        "Conceptual: identifying relevant values and who might be relevant stakeholders Using philosophical and social science theory and existing findings\n",
        "Empirical: actively engaging stakeholders’ perspectives to identify variation and commonalities\n",
        "Method: observation, surveys, interviews, focus groups Technical: proactive design to support values identified in the conceptual investigation; identify how existing technological properties support or hinder realisation of values\n",
        "\n",
        "**Trustworthiness**\n",
        "\n",
        "based on stable and effective patterns of behaviour and attitudes, indicating that the person trusted has taken our goals on board and is motivated to act in our interests.\n",
        "\n",
        "* Competence (can do)\n",
        "* Reliability (will do)\n",
        "* Dispositional (will adapt/respond adequately)\n",
        "* Interest in maintenance of positive relationship (wants to do)\n",
        "* Moral response to dependency by others (doing for moral reasons)\n",
        "* Conveys own trustworthiness proactively and appropriately to those in position of dependence (relational)\n",
        "\n",
        "**Seven key requirements for Trustworthy AI**\n",
        "\n",
        "1. human agency and oversight\n",
        "2. technical robustness and safety\n",
        "3. privacy and data governance\n",
        "4. transparency\n",
        "5. diversity, non-discrimination and fairness\n",
        "6. environmental and societal well-being\n",
        "7. accountability"
      ],
      "metadata": {
        "id": "dTXUtFfKKEYD"
      }
    }
  ]
}