{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdJPCHQcju+weTcQFyty6c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/MindMapInfoRetrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week1\n",
        "\n",
        "# Data collections\n",
        "Well structured collections of related items; items are usually atomic with a well-defined interpretation. Data retrieval involves the selection of a fixed set of data based on a well-defined query (e.g SQL, OQL).\n",
        "\n",
        "# Information collections\n",
        "Information, on the other hand, is usually semi-structured or unstructured. Information retrieval (IR) involves the retrieval of documents of natural  Language which is typically not structured and may be semantically ambiguous.\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "**Stemming**\n",
        "\n",
        "Stemming refers to the reduction to words to a potentially common root.\n",
        "Stemming involves the reduction of similar words to a common root form. Lovin’s and Porter’s algorithms are the most common.\n",
        "\n",
        "EX. Computerisation, computing, computers could all be stemmed to common form\n",
        "comput.\n",
        "\n",
        "\n",
        "**Stop word removal**\n",
        "\n",
        "This involves the removal of very frequent terms from documents.\n",
        "These terms add little to the semantics or meaning of the document.\n",
        "\n",
        "\n",
        "**Thesaurus construction**\n",
        "\n",
        "Thesauri used to try to identify synonyms within the documents. Manually or\n",
        "automatically created.\n",
        "EX. Messi, Argentina, World cup correlated\n",
        "\n",
        "**Representation**\n",
        "\n",
        "Representation and comparison technique depends on the information retrieval model\n",
        "chosen. The choice of feedback techniques is also dependent on the model chosen.\n",
        "\n",
        "\n",
        "-----------------------------------------------------------\n",
        "# IR Models\n",
        "\n",
        "**Boolean**\n",
        "  * Classical Boolean\n",
        "  * Fuzzy Set approach\n",
        "  * Extended Boolean\n",
        "\n",
        "```\n",
        "Based on set theory and the Boolean algebra. A query is viewed as a Boolean expression.\n",
        "\n",
        "Advantages >\n",
        "Clean formalism popular, widespread relatively simple\n",
        "\n",
        "Disadvantages >\n",
        "Not very good performance.\n",
        "Suffers badly from natural language effects of synonymy etc.\n",
        "No ranking of results. Harbours some difficulty in use.\n",
        "Terms in a documents are considered independent of each other.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "**Vector**\n",
        "\n",
        "  * Vector space approach\n",
        "  * Latent Semantic Indexing\n",
        "  * Neural Networks\n",
        "\n",
        "\n",
        "```\n",
        "Attempts to improve upon the Boolean model by removing the limitation of binary\n",
        "weights for index terms.\n",
        "Terms can have a non-binary weights in both queries and documents.\n",
        "Hence we can represent documents and query as n-dimensional vectors.\n",
        "We can calculate the similarity between a document and a query by calculating the similarity between the vector representations of the document and query.\n",
        "\n",
        "Advantages >\n",
        "mproved performance over the Boolean model due to weighting schemes Partial matching allowed which gives a natural ranking\n",
        "\n",
        "Disadvantages >\n",
        "Terms are considered to be mutually independent\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "**Probabilistic**\n",
        "  * Inference Network\n",
        "  * Belief Network\n",
        "  "
      ],
      "metadata": {
        "id": "ptSLqdSf0gqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 2\n",
        "\n",
        "# Evaluation of IR systems\n",
        "\n",
        "**Test Collections**\n",
        "Evaluation of IR systems is usually based on a test reference collection involving human evaluations.\n",
        "  * Test collection usually comprises:\n",
        "  * a collection of documents (D)\n",
        "  * a set of information needs that can be represented as queries\n",
        "  * a list of relevance judgements for each query-document pair\n",
        "\n",
        "Issues\n",
        "  * Can be very costly to obtain relevance judgements\n",
        "  * Crowd sourcing\n",
        "  * Pooling approaches\n",
        "  * Relevance judgements don’t have to be just binary\n",
        "  * Agreement among judges?\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "# Precision and Recal\n",
        "\n",
        "The most commonly used metrics are: precision and recall\n",
        "Given a set D and a query Q:\n",
        "Let R be the set of documents relevant to Q. Let A be the set actually returned by the system.\n",
        "\n",
        "Precision is defined as |R∩A|/|A|\n",
        "Recall is defined as |R∩A|/|R|\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HxISz16c-IbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 3\n",
        "\n",
        "# Vector Space Model\n",
        "\n",
        "\n",
        "*   We can calculate the similarity between a document and a query by calculating the similarity between the vector representations.\n",
        "\n",
        "*   We can measure this similarity by measuring the cosine of the angle between the two vectors.\n",
        "\n",
        "# Weighting\n",
        "\n",
        "* We need means to calculate the term weights in the document and query vector representations.\n",
        "* A term’s frequency within a document quantifies how well a term describes a document. The more frequent a term occurs in a document, the better it is at describing that document and vice-versa.\n",
        "* The most commonly used weighting schemes are known as tf-idf weighting schemes.\n",
        "\n",
        "------------------------------------------------------\n",
        "**Weighting schemes**\n",
        "\n",
        "* Quality of performance of information retrieval system depends on the quality of the weighting scheme\n",
        "* Want to assign high weights to those terms with a high resolving power.\n",
        "* tf*idf is one such approach where weight is increased for frequently occurring terms but decreased again for those that are frequent across the collection\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K3A0yD4vc4L0"
      }
    }
  ]
}